{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIS Practicum Project\n",
    "____________________________________\n",
    "## Impact of Extreme Weather Events on Railway Incidents\n",
    "### Determining high risk locations where monitoring stations could be installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Sources:\n",
    "\n",
    "    1. NOAA Reference Data:\n",
    "        - source: ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/\n",
    "        - local files: ghcnd-stations.txt & ghcnd-states.txt\n",
    "        - use: reference data for daily weather station files\n",
    "    2. NOAA Daily Weather Data:\n",
    "        - source: ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/\n",
    "        - local files: ghcnd_hcn.tar.gz\n",
    "        - use: granular weather data by station\n",
    "    3. U.S. Cities Data:\n",
    "        - source: https://github.com/kelvins/US-Cities-Database/blob/main/csv/us_cities.csv\n",
    "        - local files: us_cities.csv\n",
    "        - use: mapping between datasets\n",
    "    4. Railroad Grade Crossing Incident Data:\n",
    "        - source: https://data.transportation.gov/Railroads/Highway-Rail-Grade-Crossing-Accident-Data/7wn6-i5b9\n",
    "        - local files: Highway-Rail_Grade_Crossing_Accident_Data.csv\n",
    "        - use: main incident dataset\n",
    "    5. Weather Events:\n",
    "        - source: https://www.kaggle.com/sobhanmoosavi/us-weather-events\n",
    "        - local file: WeatherEvents_Jan2016-Dec2020.csv\n",
    "        - use: major U.S. weather events, 6.3m over 5yr period\n",
    "    \n",
    "Outline:\n",
    "    1. Environment setup\n",
    "    2. Data loading & Preprocessing\n",
    "    3. EDA & Visualization\n",
    "    4. Prep for scikit learn\n",
    "    5. Model Building & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Matplotlib Style:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Current Working Directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = os.getcwd()\n",
    "print(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish Constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define relevant years list for treatments\n",
    "relevant_years_list = [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign a random seed\n",
    "np.random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Preprocessing\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source 1: NOAA Reference Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_noaa_stations_data(wd):\n",
    "    \"\"\"\n",
    "    This function will load the weather station dataset from NOAA\n",
    "    this is used for mapping to rail crossing locations.\n",
    "    \n",
    "    Contains weather station reference data\n",
    "    \n",
    "    Source: ghcnd-stations.txt from NOAA ftp\n",
    "    Input: wd - working directory\n",
    "    Output: stations_df - dataframe of NOAA stations\n",
    "    \"\"\"\n",
    "    f = open(os.path.join(wd,\"ghcnd-stations.txt\"),\"r\")\n",
    "    lines = f.readlines()\n",
    "\n",
    "    # columns in the station file\n",
    "    colnames = ['ID', 'LAT', 'LON', 'ELEV', 'STATE', 'NAME', 'GSN', 'HCNCRN', 'WMOID']\n",
    "    stationlist = []\n",
    "\n",
    "    # initialize dataframe with correct columns\n",
    "    stations_df = pd.DataFrame(columns=colnames)\n",
    "\n",
    "    # iterate through stations and add them to our collection of stations if they are in the US\n",
    "    for line in lines:\n",
    "        # first 2 characters are the country code , we only care about us stations\n",
    "        if line[0:2] == 'US':\n",
    "\n",
    "            # the description of the file seemed slightly off, i tested and found these column numbers to work best\n",
    "            row = {\"ID\": line[0:11].upper(),\n",
    "                    \"LAT\": float(line[13:20]),\n",
    "                    \"LON\": float(line[21:30]),\n",
    "                    \"ELEV\": float(line[31:37]),\n",
    "                    \"STATE\": line[38:40],\n",
    "                    \"NAME\": line[41:71],\n",
    "                    \"GSN\": line[72:75],\n",
    "                    \"HCNCRN\": line[76:79],\n",
    "                    \"WMOID\": line[80:85]\n",
    "                   }\n",
    "            stationlist.append(row)\n",
    "        else:\n",
    "            pass\n",
    "    stations_df = stations_df.append(stationlist)\n",
    "    f.close()\n",
    "    \n",
    "    return stations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = load_noaa_stations_data(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### States:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_noaa_states_data(wd):\n",
    "    \"\"\"\n",
    "    This function will load the state dataset from NOAA\n",
    "    this is used for mapping to rail crossing locations.\n",
    "    \n",
    "    Contains state reference data\n",
    "    \n",
    "    Source: ghcnd-states.txt from NOAA ftp\n",
    "    Input: wd - working directory\n",
    "    Output: states_df - dataframe of NOAA states\n",
    "    \"\"\"\n",
    "    # read in states dataset to supplement weather stations data\n",
    "    f = open(os.path.join(wd,\"ghcnd-states.txt\"),\"r\")\n",
    "    lines = f.readlines()\n",
    "\n",
    "    colnames = ['CODE', 'NAME']\n",
    "\n",
    "    # create dataframe of state data\n",
    "    states_df = pd.DataFrame(columns=colnames)\n",
    "    for line in lines:\n",
    "        modline = line.strip('\\n')\n",
    "        data = {'CODE': line[0:2],\n",
    "                \"NAME\": modline[3:50]\n",
    "               }\n",
    "        states_df = states_df.append(data, ignore_index=True)    \n",
    "\n",
    "    f.close()\n",
    "    return states_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df = load_noaa_states_data(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOAA Reference Data Merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_noaa_refdata(stations_df, states_df):\n",
    "    \"\"\"\n",
    "    This function will merge the NOAA refdata\n",
    "    this is used for mapping to rail crossing locations.\n",
    "    \n",
    "    Contains state & station reference data\n",
    "    \n",
    "    Input: stations_df, states_df\n",
    "    Output: stations_plus_df - dataframe of NOAA refdata\n",
    "    \"\"\"\n",
    "    \n",
    "    # add state data to the stations dataset\n",
    "    station_plus_df = stations_df.join(states_df.set_index('CODE'), on='STATE', rsuffix='_STATE')\n",
    "\n",
    "    # create our key feature: coordinateID (wcoordinateID for weather)\n",
    "    # round latitude & longitude to 1 decimal, combine them in a tuple (lat, lon)\n",
    "    station_plus_df['wcoordinateID'] = list(zip(round(station_plus_df['LAT'],1),round(station_plus_df['LON'],1)))\n",
    "    station_plus_df = station_plus_df[['ID','ELEV','wcoordinateID']]\n",
    "    \n",
    "    return station_plus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_plus_df = merge_noaa_refdata(stations_df, states_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_plus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source 3: U.S. Cities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_us_cities_data(wd):\n",
    "    \"\"\"\n",
    "    This function will load cities data which will \n",
    "    be used to attach coordinateID to other datasets \n",
    "    which only have city or county level data.\n",
    "    Also derives county locations.\n",
    "    \n",
    "    Input: wd - working directory\n",
    "    Output: grouped_meancounties_df\n",
    "    \"\"\"\n",
    "    cities_df = pd.read_csv(os.path.join(wd,\"us_cities.csv\"))\n",
    "    \n",
    "    # standardize county and state, city is not populated for all events.\n",
    "    # one change to approach would be to include all cities + the grouped mean of each county\n",
    "    cities_df['County'] = cities_df['COUNTY'].str.upper()\n",
    "    cities_df['State'] = cities_df['STATE_NAME'].str.upper()\n",
    "\n",
    "    # subset of data that we care about, lat+lon to make coordinateID, county, state, state code to merge on\n",
    "    counties = cities_df[['County','State','LATITUDE','LONGITUDE','STATE_CODE']]\n",
    "    grouped_counties = counties.groupby(['State','County'])\n",
    "    grouped_meancounties_df = grouped_counties.mean()\n",
    "    grouped_meancounties_df = grouped_meancounties_df.reset_index()\n",
    "    grouped_meancounties_df['wcoordinateID'] = list(zip(round(grouped_meancounties_df['LATITUDE'],1),round(grouped_meancounties_df['LONGITUDE'],1)))\n",
    "    \n",
    "    return grouped_meancounties_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_meancounties_df = load_us_cities_data(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_meancounties_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source 4: Rail Crossing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rail_crossing_data(wd, grouped_meancounties_df):\n",
    "    \"\"\"\n",
    "    This function will load data for rail crossings\n",
    "    which will be used for instances for model training.\n",
    "    Will also be used to limit weather station observations\n",
    "    \n",
    "    Input: wd - working directory, grouped_meancounties_df - location base data\n",
    "    Output: rail_city_df\n",
    "    \"\"\"\n",
    "    railcrossing_df = pd.read_csv(os.path.join(wd,\"Highway-Rail_Grade_Crossing_Accident_Data.csv\"))\n",
    "    \n",
    "    # gather the fields necessary for coordinateID, as well as any  fields you want for analysis later \n",
    "    # change to approache what fields we include in refined_rr\n",
    "    refined_rr_df = railcrossing_df #[['Incident Number','Date','County Name', 'State Name']]\n",
    "\n",
    "    # drop any incident without a date\n",
    "    refined_rr_df = refined_rr_df.dropna(subset=['Date'])\n",
    "\n",
    "    # create our feature incident date, which is an integer with format: yyyymmdd \n",
    "    incident_date = refined_rr_df['Date'].str.split(' ', expand=True)\n",
    "    incident_date = incident_date[0].str.split('/', expand=True)\n",
    "    refined_rr_df['incident_date'] = (incident_date[2].astype(int) * 10000) + (incident_date[0].astype(int) * 100) + (incident_date[1].astype(int) * 1)\n",
    "\n",
    "    # merge accident data with city/county data to add coordinateID to each accident.\n",
    "    merg_rail_city_df = refined_rr_df.merge(grouped_meancounties_df, how='inner', left_on=['County Name','State Name'], right_on=['County','State'])\n",
    "    print(\"Shape of merged unfiltered rail_city dataset:  {}\".format(merg_rail_city_df.shape))\n",
    "    merg_rail_city_df = merg_rail_city_df[merg_rail_city_df['incident_date'] > 20140000]\n",
    "    merg_rail_city_df = merg_rail_city_df[['Grade Crossing ID', \n",
    "                                           'Maintenance Parent Railroad Code', \n",
    "                                           'Incident Number',\n",
    "                                           'Crossing Illuminated',\n",
    "                                           'Railroad Type',\n",
    "                                           'Track Type Code', \n",
    "                                           'incident_date', \n",
    "                                           'wcoordinateID', \n",
    "                                           'State', \n",
    "                                           'County'\n",
    "                                          ]]\n",
    "    print(\"Shape of merged filtered rail_city dataset:  {}\".format(merg_rail_city_df.shape))\n",
    "    \n",
    "    return merg_rail_city_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merg_rail_city_df = load_rail_crossing_data(wd, grouped_meancounties_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_rail(merg_rail_city_df):\n",
    "    \"\"\"\n",
    "    This function will preprocess rail df.\n",
    "    Focus is on datetime formats\n",
    "    \n",
    "    input: merg_rail_city_df\n",
    "    output: enriched merg_rail_city_df\n",
    "    \"\"\"\n",
    "    \n",
    "    merg_rail_city_df['incident_datetime'] = pd.to_datetime(merg_rail_city_df['incident_date'], format='%Y%m%d')\n",
    "    merg_rail_city_df['incident_year'] = merg_rail_city_df['incident_datetime'].dt.year\n",
    "    merg_rail_city_df['incident_month'] = merg_rail_city_df['incident_datetime'].dt.month\n",
    "    merg_rail_city_df['incident_year_month'] = merg_rail_city_df['incident_year'].astype(str) + '_' + merg_rail_city_df['incident_month'].astype(str)\n",
    "    \n",
    "    return merg_rail_city_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merg_rail_city_df = pre_process_rail(merg_rail_city_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merg_rail_city_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter Weather Stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_weather_stations(station_plus_df, merg_rail_city_df, relevant_years_list):\n",
    "    \"\"\"\n",
    "    This function will filter for relevant weather stations\n",
    "    \n",
    "    input: \n",
    "    - station_plus_df (enriched station data)\n",
    "    - merg_rail_city_df (rail incident & city data)\n",
    "    - relevant_years_list\n",
    "    output: \n",
    "    - incident_stations list\n",
    "    - merged_stations_incidents_df (filtered data for location and years)\n",
    "    \"\"\"\n",
    "\n",
    "    # dataframe of weather stations - only those that share coordinateID with an accident\n",
    "    merged_stations_incidents_df = station_plus_df.merge(merg_rail_city_df,left_on='wcoordinateID', right_on='wcoordinateID', how='inner')\n",
    "\n",
    "    # filter by state\n",
    "    target_states = ['NEW JERSEY','NEW YORK','PENNSYLVANIA','CONNECTICUT','DELAWARE','MARYLAND','MASSACHUSETTS','NEW HAMPSHIRE','VIRGINIA']\n",
    "    target_state_codes = ['NJ', 'NY', 'PA', 'CT', 'DE', 'MD', 'MA', 'NH', 'VA']\n",
    "    statefiltered_stations_incidents_df = merged_stations_incidents_df[merged_stations_incidents_df['State'].isin(target_states)]\n",
    "\n",
    "    # filter by year\n",
    "    yearstatefiltered_stations_incidents_df = statefiltered_stations_incidents_df[statefiltered_stations_incidents_df['incident_year'].isin(relevant_years_list)]\n",
    "\n",
    "    # save a list of the station IDs that were included in the merged dataframe\n",
    "    incident_stations = [x.upper() for x in yearstatefiltered_stations_incidents_df['ID'].unique()]\n",
    "\n",
    "    print(len(incident_stations))\n",
    "    \n",
    "    return incident_stations, merged_stations_incidents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incident_stations, merged_stations_incidents_df = filter_weather_stations(station_plus_df, merg_rail_city_df, relevant_years_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_stations_incidents_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_stations_incidents_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source 2: NOAA Daily Weather Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:  Source 2 needed to be loaded here in order to use the incident_stations list to filter which stations will be captured, this was done to reduce preprocessing effort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "#### IMPORTANT - You will need ~40 GB of HDD or SSD space for NOAA Data, as well as time (~2hrs depending on connection quality) for downloading + extracting noaa data \n",
    "\n",
    "1. Download all files  and move them to the directory you plan to work in (working directory / wd)\n",
    "2. Select the file ghcnd_all.tar.gz and open it with your unzipping tool (ie: WinRAR), it will take time to load due to the size (~120,000 files)\n",
    "3. Upon Completion, you will see a text file ghcnd-version.txt, and folder ghcnd_all.  \n",
    "\n",
    "Two options for the next part:\n",
    "1. Extracting all data\n",
    "2. Extracting only US data\n",
    "\n",
    "Both take time, only US data is a slightly faster but more effort up front, each option is described below.\n",
    "\n",
    "1. Extracting all data:\n",
    "- Select the folder ghcnd_all and extract to your current working directory (wd).  You will need ~40 GB  of space to be safe.  Extraction will take a while. \n",
    "\n",
    "2. Extracting only US data:\n",
    "- Select the folder ghcnd_all and open it in WinRAR/7Zip, it will take a minute to load all the files inside.  Sort the files by name. Scroll down to the prefix 'US'. Select all files beginning with 'US'. and extract them to a new folder 'ghcnd_all' in your working directory (wd/ghcnd_all). Extraction still takes a while, but this is faster than getting all 120k files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_noaa_dailies(wd):\n",
    "    '''\n",
    "    This function will load the noaa daily weather station data\n",
    "    this data contains the values associated w station ref data\n",
    "    \n",
    "    prior attempts to include this data failed because ghcnd_ghc.tar.gz is too large.\n",
    "    by limiting the number of stations included to only those where incidents occurred,\n",
    "    and by limiting the observation years from each station, we can reduce the amount of\n",
    "    memory required to process this data\n",
    "    \n",
    "    input: wd (your working directory, assuming above instructions followed)\n",
    "    output: noaa_relevant_dailies.csv (written to your wd)\n",
    "    '''\n",
    "    # with assistance from \n",
    "    # https://stackoverflow.com/questions/62165172/convert-dly-files-to-csv-using-python\n",
    "    # fields as given by the spec\n",
    "    \n",
    "    fields = [\n",
    "        [\"ID\", 1, 11],\n",
    "        [\"YEAR\", 12, 15],\n",
    "        [\"MONTH\", 16, 17],\n",
    "        [\"ELEMENT\", 18, 21]]\n",
    "\n",
    "    offset = 22\n",
    "\n",
    "    for value in range(1, 32):\n",
    "        fields.append((f\"VALUE{value}\", offset,     offset + 4))\n",
    "        fields.append((f\"MFLAG{value}\", offset + 5, offset + 5))\n",
    "        fields.append((f\"QFLAG{value}\", offset + 6, offset + 6))\n",
    "        fields.append((f\"SFLAG{value}\", offset + 7, offset + 7))\n",
    "        offset += 8\n",
    "\n",
    "    # Modify fields to use Python numbering\n",
    "    fields = [[var, start - 1, end] for var, start, end in fields]\n",
    "    fieldnames = [var for var, start, end in fields]\n",
    "\n",
    "\n",
    "    # the goal of this code is to make 1 file TOTAL from many (originally 1 per station)\n",
    "\n",
    "    # enter where you want a csv saved - it will be many Gigs\n",
    "    csv_filename = wd+'\\\\noaa_relevant_dailies.csv'\n",
    "\n",
    "    with open(csv_filename, 'w', newline='') as f_csv:\n",
    "\n",
    "        # glob.glob should aim at the folder where you extracted all the daily files, wd/ghcnd_all - do not forget to include '\\*.dly'\n",
    "        for dly_filename in glob.glob(r'C:\\Users\\thoma\\Desktop\\Rutgers MBS\\Externship Class\\Practicum\\Project\\ghcnd_all\\*.dly', recursive=True):\n",
    "            path, name = os.path.split(dly_filename)\n",
    "            station = name[:-4].upper()\n",
    "            if station in incident_stations:\n",
    "                # you could replace this with adding to a dataframe or something else, but i am running out of brain power.\n",
    "                with open(dly_filename, newline='') as f_dly:\n",
    "                    spamwriter  = csv.writer(f_csv)\n",
    "                    spamwriter.writerow(fieldnames) \n",
    "\n",
    "                    for line in f_dly:\n",
    "                        row = [line[start:end].strip() for var, start, end in fields]\n",
    "                        year = int(row[1])\n",
    "\n",
    "                        # important check to save memory, only add recent observations\n",
    "                        if year > 2014:\n",
    "                            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_noaa_dailies(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess NOAA Daily Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_noaa_dailies(wd):\n",
    "    \"\"\"\n",
    "    This function will clean the noaa_relevant_dailies data\n",
    "    \n",
    "    input: wd (working directory, will find relevant file)\n",
    "    output: final_daily_observations.csv (cleaned data)\n",
    "    \"\"\"\n",
    "    # load data written from previous function\n",
    "    df = pd.read_csv(os.path.join(wd,\"noaa_relevant_dailies.csv\"))\n",
    "    # we added a header row for every file, but we only need 1 header row. remove the others:\n",
    "    df = df[df['YEAR'] != 'YEAR']\n",
    "\n",
    "    # month and year had some strings and some ints. lets standardize\n",
    "    df['YEAR'] = pd.to_numeric(df['YEAR'])\n",
    "    df['MONTH'] = pd.to_numeric(df['MONTH'])\n",
    "\n",
    "\n",
    "    # base for transposed data\n",
    "    base = pd.DataFrame(columns=['ID','YEAR','MONTH','ELEMENT','VALUE', 'MFLAG', 'QFLAG', 'SFLAG'])\n",
    "\n",
    "    # loop through all days to partially transpose the file (day cols -> rows)\n",
    "    for i in range(1,32):\n",
    "        colnames = [f'VALUE{i}', f'MFLAG{i}', f'QFLAG{i}', f'SFLAG{i}']\n",
    "        newcolnames = ['VALUE', 'MFLAG', 'QFLAG', 'SFLAG']\n",
    "        col_order = ['ID','YEAR','MONTH','DAY','ELEMENT', colnames[0], colnames[1], colnames[2], colnames[3]]\n",
    "\n",
    "        df_new = df[['ID','YEAR','MONTH','ELEMENT', colnames[0], colnames[1], colnames[2], colnames[3]]]\n",
    "        df_new['DAY'] = i\n",
    "        df_new = df_new[col_order]\n",
    "        df_new = df_new.rename(columns={colnames[0]:newcolnames[0], colnames[1]:newcolnames[1], colnames[2]:newcolnames[2], colnames[3]:newcolnames[3]})\n",
    "        base = pd.concat([base, df_new], sort=False)\n",
    "\n",
    "\n",
    "    newcsv = base[['ID','YEAR','MONTH','DAY','ELEMENT','VALUE','MFLAG','QFLAG','SFLAG']]\n",
    "\n",
    "    daily_station_coordinates = station_plus_df[['ID','wcoordinateID']]\n",
    "    daily_final = newcsv.merge(daily_station_coordinates, left_on='ID', right_on='ID')\n",
    "    daily_final.to_csv('final_daily_observations.csv')\n",
    "    print('cleaning complete.  final shape: ', daily_final.shape, '.  reload directory to see file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_noaa_dailies(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived NOAA Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_dailies_df = pd.read_csv(os.path.join(wd,'final_daily_observations.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_dailies_df.ID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noaa_dailies_df.head().drop('Unnamed: 0', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_noaa_dailies(noaa_dailies_df):\n",
    "    \"\"\"\n",
    "    This function will filter the noaa dailies data\n",
    "    and derive a set of aggregate features for our model\n",
    "    \n",
    "    input: noaa_dailies_df (loaded and filtered)\n",
    "    output: noaa_station_aggs_df (features)\n",
    "    \"\"\"\n",
    "    # filter for non-error (-9999 indicates measurement error) and for relevant date range\n",
    "    noaa_dailies_df = noaa_dailies_df[(noaa_dailies_df['VALUE']!=-9999) & noaa_dailies_df['YEAR'].isin([2016, 2017, 2018, 2019, 2020, 2021])]\n",
    "    # create year_month aggregator\n",
    "    noaa_dailies_df['year_month'] = noaa_dailies_df['YEAR'].astype(str) + '_' + noaa_dailies_df['MONTH'].astype(str)\n",
    "    \n",
    "    # derive features\n",
    "    # max\n",
    "    MDP_df = noaa_dailies_df[noaa_dailies_df['ELEMENT']=='PRCP'].groupby(['ID','wcoordinateID', 'year_month'])['VALUE'].max().to_frame().rename(columns={'VALUE':'Max Daily Precipitation'}).reset_index()\n",
    "    SNW_df = noaa_dailies_df[noaa_dailies_df['ELEMENT']=='SNOW'].groupby(['ID','wcoordinateID', 'year_month'])['VALUE'].max().to_frame().rename(columns={'VALUE':'Max Daily Snow'}).reset_index()\n",
    "    SDP_df = noaa_dailies_df[noaa_dailies_df['ELEMENT']=='SNWD'].groupby(['ID','wcoordinateID', 'year_month'])['VALUE'].max().to_frame().rename(columns={'VALUE':'Max Daily Snow Depth'}).reset_index()\n",
    "    TMX_df = noaa_dailies_df[noaa_dailies_df['ELEMENT']=='TMAX'].groupby(['ID','wcoordinateID', 'year_month'])['VALUE'].max().to_frame().rename(columns={'VALUE':'Max Daily TempMax'}).reset_index()\n",
    "    TMN_df = noaa_dailies_df[noaa_dailies_df['ELEMENT']=='TMIN'].groupby(['ID','wcoordinateID', 'year_month'])['VALUE'].max().to_frame().rename(columns={'VALUE':'Max Daily TempMin'}).reset_index()\n",
    "    # min\n",
    "    MDP1_df = noaa_dailies_df[noaa_dailies_df['ELEMENT']=='PRCP'].groupby(['ID','wcoordinateID', 'year_month'])['VALUE'].min().to_frame().rename(columns={'VALUE':'Min Daily Precipitation'}).reset_index()\n",
    "    SNW1_df = noaa_dailies_df[noaa_dailies_df['ELEMENT']=='SNOW'].groupby(['ID','wcoordinateID', 'year_month'])['VALUE'].min().to_frame().rename(columns={'VALUE':'Min Daily Snow'}).reset_index()\n",
    "    SDP1_df = noaa_dailies_df[noaa_dailies_df['ELEMENT']=='SNWD'].groupby(['ID','wcoordinateID', 'year_month'])['VALUE'].min().to_frame().rename(columns={'VALUE':'Min Daily Snow Depth'}).reset_index()\n",
    "    TMX1_df = noaa_dailies_df[noaa_dailies_df['ELEMENT']=='TMAX'].groupby(['ID','wcoordinateID', 'year_month'])['VALUE'].min().to_frame().rename(columns={'VALUE':'Min Daily TempMax'}).reset_index()\n",
    "    TMN1_df = noaa_dailies_df[noaa_dailies_df['ELEMENT']=='TMIN'].groupby(['ID','wcoordinateID', 'year_month'])['VALUE'].min().to_frame().rename(columns={'VALUE':'Min Daily TempMin'}).reset_index()\n",
    "    # mean\n",
    "    MDP2_df = noaa_dailies_df[noaa_dailies_df['ELEMENT']=='PRCP'].groupby(['ID','wcoordinateID', 'year_month'])['VALUE'].mean().to_frame().rename(columns={'VALUE':'Mean Daily Precipitation'}).reset_index()\n",
    "    SNW2_df = noaa_dailies_df[noaa_dailies_df['ELEMENT']=='SNOW'].groupby(['ID','wcoordinateID', 'year_month'])['VALUE'].mean().to_frame().rename(columns={'VALUE':'Mean Daily Snow'}).reset_index()\n",
    "    SDP2_df = noaa_dailies_df[noaa_dailies_df['ELEMENT']=='SNWD'].groupby(['ID','wcoordinateID', 'year_month'])['VALUE'].mean().to_frame().rename(columns={'VALUE':'Mean Daily Snow Depth'}).reset_index()\n",
    "    TMX2_df = noaa_dailies_df[noaa_dailies_df['ELEMENT']=='TMAX'].groupby(['ID','wcoordinateID', 'year_month'])['VALUE'].mean().to_frame().rename(columns={'VALUE':'Mean Daily TempMax'}).reset_index()\n",
    "    TMN2_df = noaa_dailies_df[noaa_dailies_df['ELEMENT']=='TMIN'].groupby(['ID','wcoordinateID', 'year_month'])['VALUE'].mean().to_frame().rename(columns={'VALUE':'Mean Daily TempMin'}).reset_index()\n",
    "    \n",
    "    # combine data\n",
    "    noaa_station_aggs_df = MDP_df.merge(SNW_df, how='outer', on=['ID','wcoordinateID', 'year_month'])\n",
    "    noaa_station_aggs_df = noaa_station_aggs_df.merge(SDP_df, how='outer', on=['ID','wcoordinateID', 'year_month'])\n",
    "    noaa_station_aggs_df = noaa_station_aggs_df.merge(TMX_df, how='outer', on=['ID','wcoordinateID', 'year_month'])\n",
    "    noaa_station_aggs_df = noaa_station_aggs_df.merge(TMN_df, how='outer', on=['ID','wcoordinateID', 'year_month'])\n",
    "\n",
    "    noaa_station_aggs_df = noaa_station_aggs_df.merge(MDP1_df, how='outer', on=['ID','wcoordinateID', 'year_month'])\n",
    "    noaa_station_aggs_df = noaa_station_aggs_df.merge(SNW1_df, how='outer', on=['ID','wcoordinateID', 'year_month'])\n",
    "    noaa_station_aggs_df = noaa_station_aggs_df.merge(SDP1_df, how='outer', on=['ID','wcoordinateID', 'year_month'])\n",
    "    noaa_station_aggs_df = noaa_station_aggs_df.merge(TMX1_df, how='outer', on=['ID','wcoordinateID', 'year_month'])\n",
    "    noaa_station_aggs_df = noaa_station_aggs_df.merge(TMN1_df, how='outer', on=['ID','wcoordinateID', 'year_month'])\n",
    "\n",
    "    noaa_station_aggs_df = noaa_station_aggs_df.merge(MDP2_df, how='outer', on=['ID','wcoordinateID', 'year_month'])\n",
    "    noaa_station_aggs_df = noaa_station_aggs_df.merge(SNW2_df, how='outer', on=['ID','wcoordinateID', 'year_month'])\n",
    "    noaa_station_aggs_df = noaa_station_aggs_df.merge(SDP2_df, how='outer', on=['ID','wcoordinateID', 'year_month'])\n",
    "    noaa_station_aggs_df = noaa_station_aggs_df.merge(TMX2_df, how='outer', on=['ID','wcoordinateID', 'year_month'])\n",
    "    noaa_station_aggs_df = noaa_station_aggs_df.merge(TMN2_df, how='outer', on=['ID','wcoordinateID', 'year_month'])\n",
    "    \n",
    "    #rename columns for merging purposes\n",
    "    noaa_station_aggs_df.rename(columns={'year_month':'incident_year_month'}, inplace=True)\n",
    "    \n",
    "    return noaa_station_aggs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_station_aggs_df = preprocess_noaa_dailies(noaa_dailies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_station_aggs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_station_aggs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive Truth Data and Baseline Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Incident Count Agg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_inc_count(merged_stations_incidents_df):\n",
    "    \"\"\"\n",
    "    This function will derive the incident counts,\n",
    "    aggregate by location and year_month,\n",
    "    and split out reference data\n",
    "    \n",
    "    input: merged_stations_incidents_df (incident data)\n",
    "    output: incidents_df & ref_df \n",
    "    (incident counts and station_crossing ref data respectively)\n",
    "    \"\"\"\n",
    "    # get aggregated incident data\n",
    "    inc_counts_df = merged_stations_incidents_df.groupby(['wcoordinateID', 'incident_year_month'])['Incident Number'].count().to_frame().reset_index().rename(columns={'Incident Number': 'Incident Count'})\n",
    "    fin_df = merged_stations_incidents_df.merge(inc_counts_df, how=\"left\", on=['wcoordinateID', 'incident_year_month'])\n",
    "    fin_df['Incident Count'].fillna(0, inplace=True)\n",
    "    \n",
    "    # create station_crossing reference data df\n",
    "    ref_df = fin_df[['wcoordinateID',\n",
    "                'ID',\n",
    "                'Grade Crossing ID',\n",
    "                 'ELEV',\n",
    "                 'Maintenance Parent Railroad Code',\n",
    "                 'Crossing Illuminated',\n",
    "                 'Railroad Type',\n",
    "                 'Track Type Code',\n",
    "                 'State',\n",
    "                 'County'\n",
    "                ]]\n",
    "    ref_df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # create incidents df for truth data derivation\n",
    "    incidents_df = fin_df[['wcoordinateID',\n",
    "                           'ID',\n",
    "                           'Grade Crossing ID',\n",
    "                           'incident_year',\n",
    "                           'incident_year_month',\n",
    "                           'Incident Count']]\n",
    "    incidents_df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    return incidents_df, ref_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df, ref_df = derive_inc_count(merged_stations_incidents_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble Final Feature Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_station_aggs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_noaa = noaa_station_aggs_df[noaa_station_aggs_df['ID'].isin(ref_df['ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_noaa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_df = filtered_noaa.merge(ref_df[['ID','ELEV', 'Maintenance Parent Railroad Code', 'Railroad Type', 'Track Type Code', 'State', 'County']], how='left', on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_df[feature_set_df['ID'].isin(incidents_df['ID'])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_w_truth_df = feature_set_df.merge(incidents_df[['ID', 'incident_year_month', 'Incident Count']], how='left', on=['ID', 'incident_year_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_w_truth_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_w_truth_df['Incident Count'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_w_truth_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_risk_class(x):\n",
    "    \"\"\"Assigns a risk_class label.\"\"\"\n",
    "    x = int(x)\n",
    "    if x > 6:\n",
    "        label = 'High'\n",
    "    elif x > 0 & x <= 6:\n",
    "        label = 'Medium'\n",
    "    else:\n",
    "        label = 'Low'\n",
    "        \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_w_truth_df['Risk_Level'] = feature_set_w_truth_df['Incident Count'].apply(lambda x: assign_risk_class(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_w_truth_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_w_truth_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_w_truth_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA & Visualization:\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_w_truth_df.describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Station EDA & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station_crossings = merged_stations_incidents_df.groupby(['ID'])['Grade Crossing ID'].nunique().to_frame().sort_values('Grade Crossing ID', ascending=False)\n",
    "weather_station_incidents = merged_stations_incidents_df.groupby(['ID'])['Incident Number'].nunique().to_frame().sort_values('Incident Number', ascending=False)\n",
    "weather_station_stats = weather_station_crossings.merge(weather_station_incidents, how=\"outer\", on=\"ID\")\n",
    "weather_station_stats.fillna(0, inplace=True)\n",
    "weather_station_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station_stats.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station_stats.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station_stats.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_circle = dict(markerfacecolor='cyan', marker='o')\n",
    "mean_shape = dict(markerfacecolor='green', marker='D', markeredgecolor='green')\n",
    "\n",
    "df = weather_station_stats\n",
    "c = 'cyan'\n",
    "\n",
    "fig, axs = plt.subplots(1, len(df.columns), figsize=(8,10))\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.boxplot(df.iloc[:,i], boxprops=dict(color=c), capprops=dict(color=c), whiskerprops=dict(color=c), medianprops=dict(color=c), flierprops=blue_circle, showmeans=True, meanprops=mean_shape, notch=True, vert=True)\n",
    "    ax.set_title(df.columns[i], fontsize=20, fontweight='bold')\n",
    "    ax.tick_params(axis='y', labelsize=14)\n",
    "    ax.set_ylim(0, 75)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_w_truth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_w_truth_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "                        'State',\n",
    "                        'County',\n",
    "                        'Maintenance Parent Railroad Code',\n",
    "                        'Railroad Type', \n",
    "                        'Track Type Code',\n",
    "                       ]\n",
    "\n",
    "for feature in categorical_features:\n",
    "    stats_df = feature_set_w_truth_df.groupby([feature])['ID'].count().reset_index().sort_values('ID', ascending=False).head(10)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    x = np.arange(len(stats_df[feature]))\n",
    "    width = 0.7\n",
    "\n",
    "    rects1 = ax.bar(x, stats_df['ID'], width, label = 'Count of Instances')\n",
    "    #rects2 = ax.bar(x + width/2, mode2_stats_df['Total Fatalities'], width, label = 'Incidents w Fatalities')\n",
    "\n",
    "    ax.set_title('Instance Count by {} (Top 10 if >10)'.format(feature))\n",
    "    ax.set_ylabel('Count of Instances')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(stats_df[feature])\n",
    "    ax.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = feature_set_w_truth_df.groupby(['Risk_Level'])['wcoordinateID'].count().reset_index().sort_values('wcoordinateID')\n",
    "\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x = np.arange(len(stats_df['Risk_Level']))\n",
    "width = 0.7\n",
    "\n",
    "rects1 = ax.bar(x, stats_df['wcoordinateID'], width, label = 'Count of Crossings')\n",
    "#rects2 = ax.bar(x + width/2, mode2_stats_df['Total Fatalities'], width, label = 'Incidents w Fatalities')\n",
    "\n",
    "ax.set_title('Truth Data Labels for At-Grade Crossings')\n",
    "ax.set_ylabel('Count of Crossings')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(stats_df['Risk_Level'])\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_w_truth_df.ID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_w_truth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_w_truth_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_stats_df = feature_set_w_truth_df.describe().round(2).T.head(16).reset_index()\n",
    "weather_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = weather_stats_df\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,8)) \n",
    "scat = sns.scatterplot(data=df, x='mean', y='std', s=250*df['count']/(df['count'].max()), alpha=0.5, hue='index')\n",
    "\n",
    "ax.set_ylabel('Features Standard Deviation (mm or tenths of degrees C)') \n",
    "ax.set_xlabel('Feature Mean (mm or tenths of degrees C)') \n",
    "ax.set_title('Weather Station Features') \n",
    "\n",
    "plt.grid(color='grey', linestyle = '--')\n",
    "plt.ylim(0,300)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prep for SciKitLearn:\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml, make_moons, make_circles, make_classification\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR = 'white'\n",
    "plt.rcParams['axes.labelcolor'] = COLOR\n",
    "plt.rcParams['xtick.color'] = COLOR\n",
    "plt.rcParams['ytick.color'] = COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = ''\n",
    "        else:\n",
    "            title = ''\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treatments:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_2021 = feature_set_w_truth_df[(feature_set_w_truth_df['incident_year_month'].str[:4]!='2021') & \n",
    "                                        (feature_set_w_truth_df['incident_year_month'].str[:4]!='2014') &\n",
    "                                        (feature_set_w_truth_df['incident_year_month'].str[:4]!='2015')]\n",
    "test_set_2021 = feature_set_w_truth_df[feature_set_w_truth_df['incident_year_month'].str[:4]=='2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_2021.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_2021.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_2020 = feature_set_w_truth_df[(feature_set_w_truth_df['incident_year_month'].str[:4]!='2021') & \n",
    "                                        (feature_set_w_truth_df['incident_year_month'].str[:4]!='2020') &\n",
    "                                        (feature_set_w_truth_df['incident_year_month'].str[:4]!='2014')]\n",
    "test_set_2020 = feature_set_w_truth_df[feature_set_w_truth_df['incident_year_month'].str[:4]=='2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_2020.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_2020.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_2019 = feature_set_w_truth_df[(feature_set_w_truth_df['incident_year_month'].str[:4]!='2021') & \n",
    "                                        (feature_set_w_truth_df['incident_year_month'].str[:4]!='2020') &\n",
    "                                        (feature_set_w_truth_df['incident_year_month'].str[:4]!='2019')]\n",
    "test_set_2019 = feature_set_w_truth_df[feature_set_w_truth_df['incident_year_month'].str[:4]=='2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_2019.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_2019.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Building and Evaluation:\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Key Information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes to predict\n",
    "classes = ['Low', 'Medium', 'High']\n",
    "\n",
    "# set data_df = dataset\n",
    "data_df = feature_set_w_truth_df\n",
    "\n",
    "# features definition\n",
    "categorical_features = [\n",
    "                        'State',\n",
    "                        'County',\n",
    "                        'Maintenance Parent Railroad Code',\n",
    "                        'Railroad Type', \n",
    "                        'Track Type Code',\n",
    "                       ]\n",
    "\n",
    "numeric_features = [\n",
    "#                    'ELEV',\n",
    "#                    'Mean Daily Precipitation',\n",
    "#                    'Mean Daily Snow',\n",
    "#                    'Mean Daily Snow Depth',\n",
    "#                    'Mean Daily TempMax',\n",
    "#                    'Mean Daily TempMin',\n",
    "#                    'Max Daily Precipitation',\n",
    "#                    'Max Daily Snow',\n",
    "#                    'Max Daily Snow Depth',\n",
    "#                    'Max Daily TempMax',\n",
    "#                    'Max Daily TempMin',\n",
    "#                    'Min Daily Precipitation',\n",
    "#                    'Min Daily Snow',\n",
    "#                    'Min Daily Snow Depth',\n",
    "#                    'Min Daily TempMax',\n",
    "#                    'Min Daily TempMin',\n",
    "                   ]\n",
    "\n",
    "# X represents all feature columns\n",
    "X = data_df.loc[:,(categorical_features + numeric_features)]\n",
    "# note y should be a \"Risk class\" derived from # of incidents/injuries/fatalities somehow that matches 'classes' above\n",
    "y = data_df['Risk_Level']\n",
    "\n",
    "# classifiers to try\n",
    "names = [\"Decision Tree\", \"AdaBoost\", \"GradientBoost\"]\n",
    "classifiers = [DecisionTreeClassifier(max_depth=5),\n",
    "               AdaBoostClassifier(),\n",
    "               GradientBoostingClassifier(),\n",
    "              ]\n",
    "\n",
    "# training set ratios\n",
    "tsizes = [0.7,0.8,0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation of Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Class Baseline (Train/Test/Split Treatment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = -1\n",
    "\n",
    "for classifier in classifiers:\n",
    "    # print name of classifier\n",
    "    i += 1\n",
    "    print('classifier: {}'.format(names[i]))\n",
    "    # establish pipe\n",
    "    clf = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', classifier)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # establish empty tsize lists\n",
    "    tsize_precision = []\n",
    "    tsize_recall = []\n",
    "    \n",
    "    for tsize in tsizes:\n",
    "        # print tsize being tested\n",
    "        print(f'test size: {tsize}')\n",
    "        # train, test, split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tsize)\n",
    "        # fit model\n",
    "        clf.fit(X_train, y_train)\n",
    "        # get confusion matrix stats\n",
    "        y_pred = clf.predict(X_test)\n",
    "        N = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "        # note that in the above N, rows are true label, column predicted label, values indicate # of samples\n",
    "        # utilize plot confusion matrix function from earlier\n",
    "        print('f1_score:  {}'.format(f1_score(y_test, y_pred, average=\"macro\")))\n",
    "        print('precision:  {}'.format(precision_score(y_test, y_pred, average=\"macro\")))\n",
    "        print('recall:  {}'.format(recall_score(y_test, y_pred, average=\"macro\")))\n",
    "        plot_confusion_matrix(y_test, clf.predict(X_test), classes,\n",
    "                          normalize=True,\n",
    "                          title=\"Baseline TTS Treatment - {}\".format(names[i]),\n",
    "                          cmap=plt.cm.Blues)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Class Baseline (2021 Temporal Treatment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = -1\n",
    "\n",
    "for classifier in classifiers:\n",
    "    # print name of classifier\n",
    "    i += 1\n",
    "    print('classifier: {}'.format(names[i]))\n",
    "    # establish pipe\n",
    "    clf = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', classifier)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # train, test, split\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tsize)\n",
    "    X_train = train_set_2021.drop('Risk_Level', 1)\n",
    "    X_test = test_set_2021.drop('Risk_Level', 1)\n",
    "    y_train = train_set_2021['Risk_Level']\n",
    "    y_test = test_set_2021['Risk_Level']\n",
    "\n",
    "    # fit model\n",
    "    clf.fit(X_train, y_train)\n",
    "    # get confusion matrix stats\n",
    "    y_pred = clf.predict(X_test)\n",
    "    N = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "    # note that in the above N, rows are true label, column predicted label, values indicate # of samples\n",
    "    # utilize plot confusion matrix function from earlier\n",
    "    print('f1_score:  {}'.format(f1_score(y_test, y_pred, average=\"macro\")))\n",
    "    print('precision:  {}'.format(precision_score(y_test, y_pred, average=\"macro\")))\n",
    "    print('recall:  {}'.format(recall_score(y_test, y_pred, average=\"macro\")))\n",
    "    plot_confusion_matrix(y_test, clf.predict(X_test), classes,\n",
    "                      normalize=True,\n",
    "                      title=\"Baseline 2021 Treatment - {}\".format(names[i]),\n",
    "                      cmap=plt.cm.Blues)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Class Baseline (2020 Temporal Treatment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = -1\n",
    "\n",
    "for classifier in classifiers:\n",
    "    # print name of classifier\n",
    "    i += 1\n",
    "    print('classifier: {}'.format(names[i]))\n",
    "    # establish pipe\n",
    "    clf = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', classifier)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # train, test, split\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tsize)\n",
    "    X_train = train_set_2020.drop('Risk_Level', 1)\n",
    "    X_test = test_set_2020.drop('Risk_Level', 1)\n",
    "    y_train = train_set_2020['Risk_Level']\n",
    "    y_test = test_set_2020['Risk_Level']\n",
    "\n",
    "    # fit model\n",
    "    clf.fit(X_train, y_train)\n",
    "    # get confusion matrix stats\n",
    "    y_pred = clf.predict(X_test)\n",
    "    N = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "    # note that in the above N, rows are true label, column predicted label, values indicate # of samples\n",
    "    # utilize plot confusion matrix function from earlier\n",
    "    print('f1_score:  {}'.format(f1_score(y_test, y_pred, average=\"macro\")))\n",
    "    print('precision:  {}'.format(precision_score(y_test, y_pred, average=\"macro\")))\n",
    "    print('recall:  {}'.format(recall_score(y_test, y_pred, average=\"macro\")))\n",
    "    plot_confusion_matrix(y_test, clf.predict(X_test), classes,\n",
    "                      normalize=True,\n",
    "                      title=\"Baseline 2020 Treatment - {}\".format(names[i]),\n",
    "                      cmap=plt.cm.Blues)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Class Baseline (2019 Temporal Treatment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = -1\n",
    "\n",
    "for classifier in classifiers:\n",
    "    # print name of classifier\n",
    "    i += 1\n",
    "    print('classifier: {}'.format(names[i]))\n",
    "    # establish pipe\n",
    "    clf = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', classifier)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # train, test, split\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tsize)\n",
    "    X_train = train_set_2019.drop('Risk_Level', 1)\n",
    "    X_test = test_set_2019.drop('Risk_Level', 1)\n",
    "    y_train = train_set_2019['Risk_Level']\n",
    "    y_test = test_set_2019['Risk_Level']\n",
    "\n",
    "    # fit model\n",
    "    clf.fit(X_train, y_train)\n",
    "    # get confusion matrix stats\n",
    "    y_pred = clf.predict(X_test)\n",
    "    N = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "    # note that in the above N, rows are true label, column predicted label, values indicate # of samples\n",
    "    # utilize plot confusion matrix function from earlier\n",
    "    print('f1_score:  {}'.format(f1_score(y_test, y_pred, average=\"macro\")))\n",
    "    print('precision:  {}'.format(precision_score(y_test, y_pred, average=\"macro\")))\n",
    "    print('recall:  {}'.format(recall_score(y_test, y_pred, average=\"macro\")))\n",
    "    plot_confusion_matrix(y_test, clf.predict(X_test), classes,\n",
    "                      normalize=True,\n",
    "                      title=\"Baseline 2019 Treatment - {}\".format(names[i]),\n",
    "                      cmap=plt.cm.Blues)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Key Information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes to predict\n",
    "classes = ['Low', 'Medium', 'High']\n",
    "\n",
    "# set data_df = dataset\n",
    "data_df = feature_set_w_truth_df\n",
    "\n",
    "# features definition\n",
    "categorical_features = [\n",
    "#                        'State',\n",
    "#                        'County',\n",
    "#                        'Maintenance Parent Railroad Code',\n",
    "#                        'Railroad Type', \n",
    "#                        'Track Type Code',\n",
    "                       ]\n",
    "\n",
    "numeric_features = [\n",
    "                    'ELEV',\n",
    "                    'Mean Daily Precipitation',\n",
    "                    'Mean Daily Snow',\n",
    "                    'Mean Daily Snow Depth',\n",
    "                    'Mean Daily TempMax',\n",
    "                    'Mean Daily TempMin',\n",
    "                    'Max Daily Precipitation',\n",
    "                    'Max Daily Snow',\n",
    "                    'Max Daily Snow Depth',\n",
    "                    'Max Daily TempMax',\n",
    "                    'Max Daily TempMin',\n",
    "                    'Min Daily Precipitation',\n",
    "                    'Min Daily Snow',\n",
    "                    'Min Daily Snow Depth',\n",
    "                    'Min Daily TempMax',\n",
    "                    'Min Daily TempMin',\n",
    "                   ]\n",
    "\n",
    "# X represents all feature columns\n",
    "X = data_df.loc[:,(categorical_features + numeric_features)]\n",
    "# note y should be a \"Risk class\" derived from # of incidents/injuries/fatalities somehow that matches 'classes' above\n",
    "y = data_df['Risk_Level']\n",
    "\n",
    "# classifiers to try\n",
    "names = [\"Decision Tree\", \"AdaBoost\", \"GradientBoost\"]\n",
    "classifiers = [DecisionTreeClassifier(max_depth=5),\n",
    "               AdaBoostClassifier(),\n",
    "               GradientBoostingClassifier(),\n",
    "              ]\n",
    "\n",
    "# training set ratios\n",
    "tsizes = [0.7,0.8,0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation of Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Class Weather Model (Train/Test/Split Treatment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = -1\n",
    "\n",
    "for classifier in classifiers:\n",
    "    # print name of classifier\n",
    "    i += 1\n",
    "    print('classifier: {}'.format(names[i]))\n",
    "    # establish pipe\n",
    "    clf = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', classifier)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # establish empty tsize lists\n",
    "    tsize_precision = []\n",
    "    tsize_recall = []\n",
    "    \n",
    "    for tsize in tsizes:\n",
    "        # print tsize being tested\n",
    "        print(f'test size: {tsize}')\n",
    "        # train, test, split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tsize)\n",
    "        # fit model\n",
    "        clf.fit(X_train, y_train)\n",
    "        # get confusion matrix stats\n",
    "        y_pred = clf.predict(X_test)\n",
    "        N = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "        # note that in the above N, rows are true label, column predicted label, values indicate # of samples\n",
    "        # utilize plot confusion matrix function from earlier\n",
    "        print('f1_score:  {}'.format(f1_score(y_test, y_pred, average=\"macro\")))\n",
    "        print('precision:  {}'.format(precision_score(y_test, y_pred, average=\"macro\")))\n",
    "        print('recall:  {}'.format(recall_score(y_test, y_pred, average=\"macro\")))\n",
    "        plot_confusion_matrix(y_test, clf.predict(X_test), classes,\n",
    "                          normalize=True,\n",
    "                          title=\"Weather TTS Treatment - {}\".format(names[i]),\n",
    "                          cmap=plt.cm.Blues)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Class Weather Model (2021 Temporal Treatment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = -1\n",
    "\n",
    "for classifier in classifiers:\n",
    "    # print name of classifier\n",
    "    i += 1\n",
    "    print('classifier: {}'.format(names[i]))\n",
    "    # establish pipe\n",
    "    clf = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', classifier)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # train, test, split\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tsize)\n",
    "    X_train = train_set_2021.drop('Risk_Level', 1)\n",
    "    X_test = test_set_2021.drop('Risk_Level', 1)\n",
    "    y_train = train_set_2021['Risk_Level']\n",
    "    y_test = test_set_2021['Risk_Level']\n",
    "\n",
    "    # fit model\n",
    "    clf.fit(X_train, y_train)\n",
    "    # get confusion matrix stats\n",
    "    y_pred = clf.predict(X_test)\n",
    "    N = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "    # note that in the above N, rows are true label, column predicted label, values indicate # of samples\n",
    "    # utilize plot confusion matrix function from earlier\n",
    "    print('f1_score:  {}'.format(f1_score(y_test, y_pred, average=\"macro\")))\n",
    "    print('precision:  {}'.format(precision_score(y_test, y_pred, average=\"macro\")))\n",
    "    print('recall:  {}'.format(recall_score(y_test, y_pred, average=\"macro\")))\n",
    "    plot_confusion_matrix(y_test, clf.predict(X_test), classes,\n",
    "                      normalize=True,\n",
    "                      title=\"Weather 2021 Treatment - {}\".format(names[i]),\n",
    "                      cmap=plt.cm.Blues)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Class Weather Model (2020 Temporal Treatment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = -1\n",
    "\n",
    "for classifier in classifiers:\n",
    "    # print name of classifier\n",
    "    i += 1\n",
    "    print('classifier: {}'.format(names[i]))\n",
    "    # establish pipe\n",
    "    clf = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', classifier)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # train, test, split\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tsize)\n",
    "    X_train = train_set_2020.drop('Risk_Level', 1)\n",
    "    X_test = test_set_2020.drop('Risk_Level', 1)\n",
    "    y_train = train_set_2020['Risk_Level']\n",
    "    y_test = test_set_2020['Risk_Level']\n",
    "\n",
    "    # fit model\n",
    "    clf.fit(X_train, y_train)\n",
    "    # get confusion matrix stats\n",
    "    y_pred = clf.predict(X_test)\n",
    "    N = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "    # note that in the above N, rows are true label, column predicted label, values indicate # of samples\n",
    "    # utilize plot confusion matrix function from earlier\n",
    "    print('f1_score:  {}'.format(f1_score(y_test, y_pred, average=\"macro\")))\n",
    "    print('precision:  {}'.format(precision_score(y_test, y_pred, average=\"macro\")))\n",
    "    print('recall:  {}'.format(recall_score(y_test, y_pred, average=\"macro\")))\n",
    "    plot_confusion_matrix(y_test, clf.predict(X_test), classes,\n",
    "                      normalize=True,\n",
    "                      title=\"Weather 2020 Treatment - {}\".format(names[i]),\n",
    "                      cmap=plt.cm.Blues)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Class Weather Model (2019 Temporal Treatment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = -1\n",
    "\n",
    "for classifier in classifiers:\n",
    "    # print name of classifier\n",
    "    i += 1\n",
    "    print('classifier: {}'.format(names[i]))\n",
    "    # establish pipe\n",
    "    clf = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', classifier)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # train, test, split\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tsize)\n",
    "    X_train = train_set_2019.drop('Risk_Level', 1)\n",
    "    X_test = test_set_2019.drop('Risk_Level', 1)\n",
    "    y_train = train_set_2019['Risk_Level']\n",
    "    y_test = test_set_2019['Risk_Level']\n",
    "\n",
    "    # fit model\n",
    "    clf.fit(X_train, y_train)\n",
    "    # get confusion matrix stats\n",
    "    y_pred = clf.predict(X_test)\n",
    "    N = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "    # note that in the above N, rows are true label, column predicted label, values indicate # of samples\n",
    "    # utilize plot confusion matrix function from earlier\n",
    "    print('f1_score:  {}'.format(f1_score(y_test, y_pred, average=\"macro\")))\n",
    "    print('precision:  {}'.format(precision_score(y_test, y_pred, average=\"macro\")))\n",
    "    print('recall:  {}'.format(recall_score(y_test, y_pred, average=\"macro\")))\n",
    "    plot_confusion_matrix(y_test, clf.predict(X_test), classes,\n",
    "                      normalize=True,\n",
    "                      title=\"Weather 2019 Treatment - {}\".format(names[i]),\n",
    "                      cmap=plt.cm.Blues)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Key Information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes to predict\n",
    "classes = ['Low', 'Medium', 'High']\n",
    "\n",
    "# set data_df = dataset\n",
    "data_df = feature_set_w_truth_df\n",
    "\n",
    "# features definition\n",
    "categorical_features = [\n",
    "                        'State',\n",
    "                        'County',\n",
    "                        'Maintenance Parent Railroad Code',\n",
    "                        'Railroad Type', \n",
    "                        'Track Type Code',\n",
    "                       ]\n",
    "\n",
    "numeric_features = [\n",
    "                    'ELEV',\n",
    "                    'Mean Daily Precipitation',\n",
    "                    'Mean Daily Snow',\n",
    "                    'Mean Daily Snow Depth',\n",
    "                    'Mean Daily TempMax',\n",
    "                    'Mean Daily TempMin',\n",
    "                    'Max Daily Precipitation',\n",
    "                    'Max Daily Snow',\n",
    "                    'Max Daily Snow Depth',\n",
    "                    'Max Daily TempMax',\n",
    "                    'Max Daily TempMin',\n",
    "                    'Min Daily Precipitation',\n",
    "                    'Min Daily Snow',\n",
    "                    'Min Daily Snow Depth',\n",
    "                    'Min Daily TempMax',\n",
    "                    'Min Daily TempMin',\n",
    "                   ]\n",
    "\n",
    "# X represents all feature columns\n",
    "X = data_df.loc[:,(categorical_features + numeric_features)]\n",
    "# note y should be a \"Risk class\" derived from # of incidents/injuries/fatalities somehow that matches 'classes' above\n",
    "y = data_df['Risk_Level']\n",
    "\n",
    "# classifiers to try\n",
    "names = [\"Decision Tree\", \"AdaBoost\", \"GradientBoost\"]\n",
    "classifiers = [DecisionTreeClassifier(max_depth=5),\n",
    "               AdaBoostClassifier(),\n",
    "               GradientBoostingClassifier(),\n",
    "              ]\n",
    "\n",
    "# training set ratios\n",
    "tsizes = [0.7,0.8,0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation of Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Class Combined Model (Train/Test/Split Treatment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = -1\n",
    "\n",
    "for classifier in classifiers:\n",
    "    # print name of classifier\n",
    "    i += 1\n",
    "    print('classifier: {}'.format(names[i]))\n",
    "    # establish pipe\n",
    "    clf = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', classifier)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # establish empty tsize lists\n",
    "    tsize_precision = []\n",
    "    tsize_recall = []\n",
    "    \n",
    "    for tsize in tsizes:\n",
    "        # print tsize being tested\n",
    "        print(f'test size: {tsize}')\n",
    "        # train, test, split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tsize)\n",
    "        # fit model\n",
    "        clf.fit(X_train, y_train)\n",
    "        # get confusion matrix stats\n",
    "        y_pred = clf.predict(X_test)\n",
    "        N = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "        # note that in the above N, rows are true label, column predicted label, values indicate # of samples\n",
    "        # utilize plot confusion matrix function from earlier\n",
    "        print('f1_score:  {}'.format(f1_score(y_test, y_pred, average=\"macro\")))\n",
    "        print('precision:  {}'.format(precision_score(y_test, y_pred, average=\"macro\")))\n",
    "        print('recall:  {}'.format(recall_score(y_test, y_pred, average=\"macro\")))\n",
    "        plot_confusion_matrix(y_test, clf.predict(X_test), classes,\n",
    "                          normalize=True,\n",
    "                          title=\"Combined TTS Treatment - {}\".format(names[i]),\n",
    "                          cmap=plt.cm.Blues)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Class Combined Model (2021 Temporal Treatment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = -1\n",
    "\n",
    "for classifier in classifiers:\n",
    "    # print name of classifier\n",
    "    i += 1\n",
    "    print('classifier: {}'.format(names[i]))\n",
    "    # establish pipe\n",
    "    clf = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', classifier)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # train, test, split\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tsize)\n",
    "    X_train = train_set_2021.drop('Risk_Level', 1)\n",
    "    X_test = test_set_2021.drop('Risk_Level', 1)\n",
    "    y_train = train_set_2021['Risk_Level']\n",
    "    y_test = test_set_2021['Risk_Level']\n",
    "\n",
    "    # fit model\n",
    "    clf.fit(X_train, y_train)\n",
    "    # get confusion matrix stats\n",
    "    y_pred = clf.predict(X_test)\n",
    "    N = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "    # note that in the above N, rows are true label, column predicted label, values indicate # of samples\n",
    "    # utilize plot confusion matrix function from earlier\n",
    "    print('f1_score:  {}'.format(f1_score(y_test, y_pred, average=\"macro\")))\n",
    "    print('precision:  {}'.format(precision_score(y_test, y_pred, average=\"macro\")))\n",
    "    print('recall:  {}'.format(recall_score(y_test, y_pred, average=\"macro\")))\n",
    "    plot_confusion_matrix(y_test, clf.predict(X_test), classes,\n",
    "                      normalize=True,\n",
    "                      title=\"Combined 2021 Treatment - {}\".format(names[i]),\n",
    "                      cmap=plt.cm.Blues)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Class  Combined Model (2020 Temporal Treatment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = -1\n",
    "\n",
    "for classifier in classifiers:\n",
    "    # print name of classifier\n",
    "    i += 1\n",
    "    print('classifier: {}'.format(names[i]))\n",
    "    # establish pipe\n",
    "    clf = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', classifier)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # train, test, split\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tsize)\n",
    "    X_train = train_set_2020.drop('Risk_Level', 1)\n",
    "    X_test = test_set_2020.drop('Risk_Level', 1)\n",
    "    y_train = train_set_2020['Risk_Level']\n",
    "    y_test = test_set_2020['Risk_Level']\n",
    "\n",
    "    # fit model\n",
    "    clf.fit(X_train, y_train)\n",
    "    # get confusion matrix stats\n",
    "    y_pred = clf.predict(X_test)\n",
    "    N = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "    # note that in the above N, rows are true label, column predicted label, values indicate # of samples\n",
    "    # utilize plot confusion matrix function from earlier\n",
    "    print('f1_score:  {}'.format(f1_score(y_test, y_pred, average=\"macro\")))\n",
    "    print('precision:  {}'.format(precision_score(y_test, y_pred, average=\"macro\")))\n",
    "    print('recall:  {}'.format(recall_score(y_test, y_pred, average=\"macro\")))\n",
    "    plot_confusion_matrix(y_test, clf.predict(X_test), classes,\n",
    "                      normalize=True,\n",
    "                      title=\"Combined 2020 Treatment - {}\".format(names[i]),\n",
    "                      cmap=plt.cm.Blues)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Class Combined Model (2019 Temporal Treatment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = -1\n",
    "\n",
    "for classifier in classifiers:\n",
    "    # print name of classifier\n",
    "    i += 1\n",
    "    print('classifier: {}'.format(names[i]))\n",
    "    # establish pipe\n",
    "    clf = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', classifier)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # train, test, split\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tsize)\n",
    "    X_train = train_set_2019.drop('Risk_Level', 1)\n",
    "    X_test = test_set_2019.drop('Risk_Level', 1)\n",
    "    y_train = train_set_2019['Risk_Level']\n",
    "    y_test = test_set_2019['Risk_Level']\n",
    "\n",
    "    # fit model\n",
    "    clf.fit(X_train, y_train)\n",
    "    # get confusion matrix stats\n",
    "    y_pred = clf.predict(X_test)\n",
    "    N = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "    # note that in the above N, rows are true label, column predicted label, values indicate # of samples\n",
    "    # utilize plot confusion matrix function from earlier\n",
    "    print('f1_score:  {}'.format(f1_score(y_test, y_pred, average=\"macro\")))\n",
    "    print('precision:  {}'.format(precision_score(y_test, y_pred, average=\"macro\")))\n",
    "    print('recall:  {}'.format(recall_score(y_test, y_pred, average=\"macro\")))\n",
    "    plot_confusion_matrix(y_test, clf.predict(X_test), classes,\n",
    "                      normalize=True,\n",
    "                      title=\"Combined 2019 Treatment - {}\".format(names[i]),\n",
    "                      cmap=plt.cm.Blues)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
